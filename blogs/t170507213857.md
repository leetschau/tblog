# Using scikit-learn & pandas on Spark Cluster
Tags: sklearn; pandas; spark; python; anaconda; cdh

------

With method 'Create a Temporary Local Repository' described in
[Creating and Using a Parcel Repository for Cloudera Manager][cupr],
we can copy anaconda parcel files to cdh manager host,
and install anaconda to all the nodes in spark cluster.
Then run python scripts with
`PYSPARK_PYTHON=/opt/cloudera/parcels/Anaconda/bin/python spark-submit pyspark_script.py`
according to [Using the Anaconda parcel][uap].

# Install Anaconda with Local Parcel

Download 3 files: Anaconda-4.1.1-el6.parcel, Anaconda-4.1.1-el6.parcel.sha and
manifest.json from [Anaconda CDH Parcel Repo][anap] according to
[Using the Anaconda parcel][uap] to local disk, copy them to cdh manager.


[cupr]: https://www.cloudera.com/documentation/enterprise/5-3-x/topics/cm_ig_create_local_parcel_repo.html
[uap]: https://docs.continuum.io/anaconda/cloudera
[anap]: https://repo.continuum.io/pkgs/misc/parcels/
