# 用lxml模块解析JUnit生成的测试报告
Tags: JUnit;Python;xPath;lxml;HTML;zip

------

JUnit的测试结果首先保存在xml文档中，然后生成html格式的测试报告，这份报告中的数据是用一段javascript代码根据 xml文档的数据 计算出来的，因此我们要获取测试结果数据，就只能分析html文档，这方面lxml模块（codespeak.net/lxml/）的功能比较令人满意，利用lxml的xpath语法可以方便地得到某个标签的内容，下面是一个分析样例文本：

 <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"> 

 <html xmlns:lxslt="http://xml.apache.org/xslt" xmlns:stringutils="xalan://org.apache.tools.ant.util.StringUtils"> 

 <head> 

 <META http-equiv="Content-Type" content="text/html; charset=US-ASCII"> 

 <title>Unit Test Results.</title> 

 <script type="text/javascript" language="JavaScript"> 

 ...(1000多行) 

 </script> 

 </head> 

 <body> 

 <a name="top"></a> 

 <h1>Unit Test Results.</h1> 

 <table width="100%"> 

 <tr> 

 <td align="left"></td><td ....</td> 

 </tr> 

 </table> 

 <hr size="1"> 

 <h2>Summary</h2> 

 <table class="details" border="0" cellpadding="5" cellspacing="2" width="95%"> 

 <tr valign="top"> 

 <th>Tests</th><th>Failures</th><th>Errors</th><th>Success rate</th><th>Time</th> 

 </tr> 

 <tr valign="top" class="Error"> 

 <td>24</td><td>0</td><td>24</td><td>0.00%</td><td>0.155</td> 

 </tr> 

 </table> 

 <table ...> 

 <tr ...> 

 </tr> 

 </table> 

 ... 

 </body> 

 </html> 

效果见下图：

 

 

解析html的目的是取出文本中黑体字表示的数据。

解析函数是：

 from lxml import html 

 def parseJUnitReport(html_filename): 

 html_doc = html.parse(html_filename).getroot() 

 res_tbl = html_doc.xpath("//html//body//table")[1] 

 test_item_names = [k.text for k in res_tbl.xpath('.//tr//th')] # list comprehension 

 test_datasets = [k.text for k in res_tbl.xpath('.//tr//td')] 

 return dict(zip(test_item_names,test_datasets)) 

测试代码：

 aa = 'e:\\BVT\\GODU-BVT\\GCIF\\build\\GAPI\\build\\result\\junit\\junit-noframes.html' 

 print build.parseJUnitReport(aa) 

运行结果如下：

 {'Failures': '0', 'Tests': '24', 'Errors': '24', 'Success rate': '0.00%', 'Time': '0.155'} 

从解析函数可以看到：

导入lxml.html后，其parse方法的参数是一个文件路径字符串，用xpath()方法得到的是一个包含<body>内所有的<table>的list，由于目标table位于第二位，所以取[1]得到table对象res_tbl，然后在它的下面取<tr>里的<th>，得到标题行，对于每个得到的节点，需要用它的text属性得到文本内容，这里使用了list的comprehension功能，用一行代码就取到每个元素的text属性并组成了新的list（test_item_names和test_datasets），然后用zip方法将两个list组合成了一个list，再用dict方法将list转换成了字典。